{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38c9d771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Decoder\n",
    "from models import Encoder\n",
    "from models import Joint_Representaion_Learner\n",
    "from models import Seq2Seq\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda8dffc",
   "metadata": {},
   "source": [
    "# Setara Opt Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c50170ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'pos_attention' : False,\n",
    "    'enhance_input' : 2,\n",
    "    'watch' : 0,\n",
    "    'num_hidden_layers_decoder' : 1,\n",
    "    'decoding_type' : 'ARFormer',\n",
    "    'decoder' : 'BertDecoder',\n",
    "    'vocab_size' : 100,\n",
    "    'dim_hidden' : 512,\n",
    "    'max_len' : 30,\n",
    "    'with_category' : True,\n",
    "    'num_category' : 20,\n",
    "    'layer_norm_eps' : 0.00001,\n",
    "    'hidden_dropout_prob' : 0.5,\n",
    "    'num_attention_heads' : 8,\n",
    "    'attention_probs_dropout_prob' : 0.0,\n",
    "    'with_layernorm' : False,\n",
    "    'intermediate_size' : 2048,\n",
    "    'hidden_act' : 'gelu_new'\n",
    "}\n",
    "\n",
    "opt = {\n",
    "    'encoder' : 'Encoder_HighWay',\n",
    "    'modality' : 'mio',\n",
    "    'dim_m' : 2048,\n",
    "    'dim_i' : 1536,\n",
    "    'dim_o' : 1024,\n",
    "    'dim_hidden' : 512,\n",
    "    'no_encoder_bn' : False,\n",
    "    'vocab_size' : 100,\n",
    "    'pos_attention' : False,\n",
    "    'enhance_input' : 2,\n",
    "    'watch' : 0,\n",
    "    'num_hidden_layers_decoder' : 1,\n",
    "    'decoding_type' : 'ARFormer',\n",
    "    'decoder' : 'BertDecoder',\n",
    "    'vocab_size' : 100,\n",
    "    'dim_hidden' : 512,\n",
    "    'max_len' : 30,\n",
    "    'with_category' : True,\n",
    "    'num_category' : 20,\n",
    "    'layer_norm_eps' : 0.00001,\n",
    "    'hidden_dropout_prob' : 0.5,\n",
    "    'num_attention_heads' : 8,\n",
    "    'attention_probs_dropout_prob' : 0.0,\n",
    "    'with_layernorm' : False,\n",
    "    'intermediate_size' : 2048,\n",
    "    'hidden_act' : 'gelu_new'\n",
    "}\n",
    "\n",
    "batch_size = 8\n",
    "frame_len = 6\n",
    "num_objs = 5\n",
    "seq_len = 16\n",
    "feat_dim = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a5d9a0",
   "metadata": {},
   "source": [
    "# Encoder Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c6e7b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "m = torch.randn(batch_size, frame_len, 2048)\n",
    "i = torch.randn(batch_size, frame_len, 1536)\n",
    "o = torch.randn(batch_size, frame_len, num_objs, 1024)\n",
    "\n",
    "feats = [m, i, o]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0580baa",
   "metadata": {},
   "source": [
    "# Deklarasi Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e0463c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder_HighWay(\n",
       "  (Encoder_M): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (1): HighWay(\n",
       "      (w1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (w2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (tanh): Tanh()\n",
       "    )\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (Encoder_I): Sequential(\n",
       "    (0): Linear(in_features=1536, out_features=512, bias=True)\n",
       "    (1): HighWay(\n",
       "      (w1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (w2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (tanh): Tanh()\n",
       "    )\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (Encoder_O): ORG(\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (adjacency_dropout): Dropout(p=0.5, inplace=False)\n",
       "    (object_projection): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (sigma_r): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (psi_r): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (w_r): Linear(in_features=1024, out_features=512, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = getattr(Encoder, opt['encoder'], None)(opt)\n",
    "encoder.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891d5c62",
   "metadata": {},
   "source": [
    "# Forward Pass Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6b77c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_output, enc_hidden = encoder(feats) ## AMAN BERJALAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d8d78ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape untuk output enhanced object features torch.Size([8, 6, 5, 512]) \n",
      "Shape untuk output proyeksi object features torch.Size([8, 6, 5, 512])\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape untuk output enhanced object features {} \\n\\\n",
    "Shape untuk output proyeksi object features {}\".format(enc_output[-1][0].shape, enc_output[-1][1].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9723b3ec",
   "metadata": {},
   "source": [
    "# Joint Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42d48a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_size = [opt['dim_hidden']] * (len(opt['modality']))\n",
    "join_representation_learner = Joint_Representaion_Learner(feats_size, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24d1eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_output, enc_hidden, enc_obj_output = join_representation_learner(enc_output, enc_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2915356f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 12, 512])\n",
      "torch.Size([8, 512])\n",
      "torch.Size([8, 6, 5, 512]) torch.Size([8, 6, 5, 512])\n"
     ]
    }
   ],
   "source": [
    "print(enc_output.shape)\n",
    "print(enc_hidden.shape)\n",
    "print(enc_obj_output[0].shape, enc_obj_output[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fa7186",
   "metadata": {},
   "source": [
    "## Ditampung di Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ec9ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "results['enc_output'] = enc_output # ini tuh udah tensor yang disimpan di dict\n",
    "results['enc_hidden'] = enc_hidden # ini juga udah tensor\n",
    "results['enc_obj_output'] = enc_obj_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f30ecc2",
   "metadata": {},
   "source": [
    "# Deklarasi Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22f49f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertDecoder(\n",
       "  (embedding): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(100, 512, padding_idx=0)\n",
       "    (position_embeddings): Embedding(30, 512)\n",
       "    (category_embeddings): Embedding(20, 512)\n",
       "    (LayerNorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (layer): ModuleList(\n",
       "    (0): BertLayer(\n",
       "      (attention): BertAttention(\n",
       "        (self): BertSelfAttention(\n",
       "          (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (output): BertSelfOutput(\n",
       "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (attend_to_enc_output): BertAttention(\n",
       "        (self): BertSelfAttention(\n",
       "          (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (output): BertSelfOutput(\n",
       "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (attend_to_enc_obj_output): BertAttention(\n",
       "        (self): BertSelfAttention(\n",
       "          (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (output): BertSelfOutput(\n",
       "          (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (intermediate): BertIntermediate(\n",
       "        (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "      )\n",
       "      (output): BertOutput(\n",
       "        (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = getattr(Decoder, config['decoder'], None)(config)\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5293cac9",
   "metadata": {},
   "source": [
    "# Deklarasi Data yang Dibutuhkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b58645a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "tgt_tokens = torch.randint(0, config['vocab_size']-1, (batch_size, seq_len))\n",
    "category = torch.LongTensor([2])\n",
    "decoding_type = config['decoding_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e31f3c",
   "metadata": {},
   "source": [
    "# Info Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e0bd69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('MSRVTT/info_corpus.pkl', 'rb') as f:\n",
    "    info_corpus = pickle.load(f)\n",
    "\n",
    "# ambil index to word dictionary\n",
    "i2w = info_corpus['info']['itow']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70abeb8b",
   "metadata": {},
   "source": [
    "Preparation before feedigng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acc99b4",
   "metadata": {},
   "source": [
    "### Modified Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40128698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_object_variable(r_feats, r_hat):\n",
    "        '''\n",
    "        align object modul according to ORG-TRL Paper\n",
    "        refers = https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_Object_Relational_Graph_With_Teacher-Recommended_Learning_for_Video_Captioning_CVPR_2020_paper.pdf\n",
    "        args:\n",
    "        object_variable : This is object features exctracted from Faster RCNN\n",
    "        output:\n",
    "        aligned_object_variable\n",
    "        '''\n",
    "        ## Mengambil anchor frame sebagai acuan untuk setiap objek\n",
    "        ## Memisahkan anchor frame dari keseluruhan fitur objek\n",
    "        anchor_frame = r_feats[:, 0]\n",
    "        next_frame = r_feats[:, 1:r_feats.size(1)]\n",
    "        \n",
    "        ## menghitung cosine similarity scores\n",
    "        ## matmul( achor_frame, next_frame ) / | anchor_frame | * | next_frame |\n",
    "        similarity_score = (torch.matmul(anchor_frame.unsqueeze(1), next_frame.transpose(2, -1)) / \\\n",
    "                            (torch.norm(anchor_frame.unsqueeze(1), dim=-1)[:, :, :, None] * \\\n",
    "                            torch.norm(next_frame, dim=-1)[:, :, None, :]))\n",
    "\n",
    "        aligned_frames = torch.gather(r_hat[:, 1:r_hat.size(1)], \n",
    "                                      dim=2, \n",
    "                                      index=similarity_score.topk(1, -1)[1].\\\n",
    "                                      expand(-1, -1, -1, r_hat.size(-1)))\n",
    "\n",
    "        return torch.cat([r_hat[:, 0].unsqueeze(1), aligned_frames], dim=1)\n",
    "\n",
    "\n",
    "def prepare_inputs_for_decoder(encoder_outputs, category):\n",
    "    input_keys_for_decoder = ['enc_output', 'enc_obj_output']\n",
    "\n",
    "    inputs_for_decoder = {'category': category}\n",
    "    for key in input_keys_for_decoder:\n",
    "        inputs_for_decoder[key] = encoder_outputs[key] # di sini udah ambil tensor\n",
    "\n",
    "    if isinstance(inputs_for_decoder['enc_output'], list):\n",
    "        assert len(inputs_for_decoder['enc_output']) == 1\n",
    "        inputs_for_decoder['enc_output'] = inputs_for_decoder['enc_output'][0]\n",
    "    \n",
    "    if isinstance(inputs_for_decoder['enc_obj_output'], tuple):\n",
    "        assert len(inputs_for_decoder['enc_obj_output']) == 2\n",
    "        b_size, f_len, n_obj, _ = inputs_for_decoder['enc_obj_output'][1].size()\n",
    "        inputs_for_decoder['enc_obj_output'] = align_object_variable(inputs_for_decoder['enc_obj_output'][0],\n",
    "                                                                     inputs_for_decoder['enc_obj_output'][1]).view(b_size, f_len * n_obj, -1)\n",
    "\n",
    "    return inputs_for_decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8044820b",
   "metadata": {},
   "source": [
    "# Rerun this cell if Data is Updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3a33313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['category', 'enc_output', 'enc_obj_output'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_for_decoder = prepare_inputs_for_decoder(results, category)\n",
    "tgt_tokens = [item[:, :-1] for item in tgt_tokens] if isinstance(tgt_tokens, list) else tgt_tokens[:, :-1]\n",
    "inputs_for_decoder.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b3b8729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 30, 512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_for_decoder['enc_obj_output'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93e2bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states, embs, *_ = decoder( \n",
    "    tgt_seq=tgt_tokens, \n",
    "    decoding_type=decoding_type,\n",
    "    output_attentions=False,\n",
    "    **inputs_for_decoder # difeed setiap key value pairs ke forward method decoder\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71732e32",
   "metadata": {},
   "source": [
    "# Connecting All the Modules\n",
    "1. Connecting all the modules\n",
    "2. Checking the forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f22e5443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Decoder\n",
    "from models import Encoder\n",
    "from models import Joint_Representaion_Learner\n",
    "from models import Seq2Seq\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e6c05dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'pos_attention' : False,\n",
    "    'enhance_input' : 2,\n",
    "    'watch' : 0,\n",
    "    'num_hidden_layers_decoder' : 1,\n",
    "    'decoding_type' : 'ARFormer',\n",
    "    'decoder' : 'BertDecoder',\n",
    "    'vocab_size' : 100,\n",
    "    'dim_hidden' : 512,\n",
    "    'max_len' : 30,\n",
    "    'with_category' : True,\n",
    "    'num_category' : 20,\n",
    "    'layer_norm_eps' : 0.00001,\n",
    "    'hidden_dropout_prob' : 0.5,\n",
    "    'num_attention_heads' : 8,\n",
    "    'attention_probs_dropout_prob' : 0.0,\n",
    "    'with_layernorm' : False,\n",
    "    'intermediate_size' : 2048,\n",
    "    'hidden_act' : 'gelu_new'\n",
    "}\n",
    "\n",
    "opt = {\n",
    "    'encoder' : 'Encoder_HighWay',\n",
    "    'modality' : 'mio',\n",
    "    'dim_m' : 2048,\n",
    "    'dim_i' : 1536,\n",
    "    'dim_o' : 1024,\n",
    "    'dim_hidden' : 512,\n",
    "    'no_encoder_bn' : False,\n",
    "    'vocab_size' : 100,\n",
    "    'pos_attention' : False,\n",
    "    'enhance_input' : 2,\n",
    "    'watch' : 0,\n",
    "    'num_hidden_layers_decoder' : 1,\n",
    "    'decoding_type' : 'ARFormer',\n",
    "    'decoder' : 'BertDecoder',\n",
    "    'vocab_size' : 100,\n",
    "    'dim_hidden' : 512,\n",
    "    'max_len' : 30,\n",
    "    'with_category' : True,\n",
    "    'num_category' : 20,\n",
    "    'layer_norm_eps' : 0.00001,\n",
    "    'hidden_dropout_prob' : 0.5,\n",
    "    'num_attention_heads' : 8,\n",
    "    'attention_probs_dropout_prob' : 0.0,\n",
    "    'with_layernorm' : False,\n",
    "    'intermediate_size' : 2048,\n",
    "    'hidden_act' : 'gelu_new'\n",
    "}\n",
    "\n",
    "batch_size = 8\n",
    "frame_len = 6\n",
    "num_objs = 5\n",
    "seq_len = 16\n",
    "feat_dim = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5f6d418",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = getattr(Encoder, opt['encoder'], None)(opt)\n",
    "feats_size = [opt['dim_hidden']] * (len(opt['modality']))\n",
    "joint_representation_learner = Joint_Representaion_Learner(feats_size, opt)\n",
    "decoder = getattr(Decoder, config['decoder'], None)(config)\n",
    "tgt_word_prj = nn.Linear(opt[\"dim_hidden\"], opt[\"vocab_size\"], bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ca2a55",
   "metadata": {},
   "source": [
    "## Instantiate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df8f64e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(\n",
    "        opt=opt,\n",
    "        preEncoder=None, #None\n",
    "        encoder=encoder,\n",
    "        joint_representation_learner=joint_representation_learner,\n",
    "        auxiliary_task_predictor=None, #None\n",
    "        decoder=decoder,\n",
    "        tgt_word_prj=tgt_word_prj,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca7614f",
   "metadata": {},
   "source": [
    "## Preparing Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c2b819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "m = torch.randn(batch_size, frame_len, 2048)\n",
    "i = torch.randn(batch_size, frame_len, 1536)\n",
    "o = torch.randn(batch_size, frame_len, num_objs, 1024)\n",
    "\n",
    "feats = [m, i, o]\n",
    "\n",
    "tokens = torch.randint(0, config['vocab_size']-1, (batch_size, seq_len))\n",
    "category = torch.randint(0, 19, (1,)).long()\n",
    "decoding_type = config['decoding_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8612a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('MSRVTT/info_corpus.pkl', 'rb') as f:\n",
    "    info_corpus = pickle.load(f)\n",
    "\n",
    "# ambil index to word dictionary\n",
    "vocab = info_corpus['info']['itow']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49456bf",
   "metadata": {},
   "source": [
    "## Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0df2d914",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(feats=feats,\n",
    "                tgt_tokens=tokens, \n",
    "                category=category,\n",
    "                opt=opt,\n",
    "                vocab=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acebd1f4",
   "metadata": {},
   "source": [
    "### Forward Pass TEST is Passed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac2100d",
   "metadata": {},
   "source": [
    "# Original Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7e2fbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_inputs_for_decoder(encoder_outputs, category):\n",
    "    input_keys_for_decoder = ['enc_output']\n",
    "\n",
    "    inputs_for_decoder = {'category': category}\n",
    "    for key in input_keys_for_decoder:\n",
    "        inputs_for_decoder[key] = encoder_outputs[key] # di sini udah ambil tensor\n",
    "\n",
    "    if isinstance(inputs_for_decoder['enc_output'], list):\n",
    "        assert len(inputs_for_decoder['enc_output']) == 1\n",
    "        inputs_for_decoder['enc_output'] = inputs_for_decoder['enc_output'][0]\n",
    "\n",
    "    return inputs_for_decoder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
